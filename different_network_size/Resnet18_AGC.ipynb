{"cells":[{"cell_type":"markdown","metadata":{"id":"qUipPHQjrAOt"},"source":["#Data preparation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5292,"status":"ok","timestamp":1642890267466,"user":{"displayName":"Mathieu Jacques","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuqmYelZ_Kv6yga8GgHY07sH9ye4ZTi2sODQXkhQ=s64","userId":"02992467458977810224"},"user_tz":-60},"id":"VQUnNW_8q8fZ","outputId":"efd4066c-3b3d-4db8-8b38-8f3d985df6fa"},"outputs":[],"source":["#@title Print TF version and GPU stats\n","import tensorflow as tf\n","print('TensorFlow version:', tf.__version__)\n","\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","   raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name), '', sep='\\n')\n","!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4310,"status":"ok","timestamp":1642890271759,"user":{"displayName":"Mathieu Jacques","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuqmYelZ_Kv6yga8GgHY07sH9ye4ZTi2sODQXkhQ=s64","userId":"02992467458977810224"},"user_tz":-60},"id":"TSAMjnNbq_Si","outputId":"cd448625-316b-4311-d6ee-e8604c79e514"},"outputs":[],"source":["from tensorflow.keras.datasets import cifar10\n","(train_X, train_y), (test_X, test_y) = cifar10.load_data()"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1642890271760,"user":{"displayName":"Mathieu Jacques","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuqmYelZ_Kv6yga8GgHY07sH9ye4ZTi2sODQXkhQ=s64","userId":"02992467458977810224"},"user_tz":-60},"id":"mzTppaOlHlMn"},"outputs":[],"source":["#We need to make onehot vectors out of the labels\n","from tensorflow.keras.utils import to_categorical\n","train_y = to_categorical(train_y,num_classes=10)\n","test_y = to_categorical(test_y,num_classes=10)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":485,"status":"ok","timestamp":1642890272237,"user":{"displayName":"Mathieu Jacques","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuqmYelZ_Kv6yga8GgHY07sH9ye4ZTi2sODQXkhQ=s64","userId":"02992467458977810224"},"user_tz":-60},"id":"4r8oYIlwrjQQ"},"outputs":[],"source":["#@title Data augmentation\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","batch_size = 512\n","\n","# All images will be rescaled by 1./255\n","train_datagen = ImageDataGenerator(rescale=1./255,\n","                                   rotation_range=20,\n","                                   width_shift_range=0.1,\n","                                   height_shift_range=0.1,\n","                                   zoom_range=0.4,\n","                                   brightness_range=(.5, 1.5),\n","                                   horizontal_flip=True,\n","                                   vertical_flip=True,\n","                                   fill_mode='nearest')\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Flow training images in batches using train_datagen generator\n","train_generator = train_datagen.flow(\n","                    train_X, train_y,\n","                    batch_size=batch_size,\n","                    shuffle=True)\n","\n","num_classes = train_generator.num_classes\n","\n","# Flow test images in batches using val_datagen generator\n","test_generator = test_datagen.flow(\n","                    test_X, test_y,\n","                    batch_size=batch_size,\n","                    shuffle=True)\n","\n","train_steps = len(train_generator)\n","test_steps = len(test_generator)"]},{"cell_type":"markdown","metadata":{"id":"HfbfHXFYrJ4v"},"source":["#ResNet18 model"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1642890272238,"user":{"displayName":"Mathieu Jacques","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuqmYelZ_Kv6yga8GgHY07sH9ye4ZTi2sODQXkhQ=s64","userId":"02992467458977810224"},"user_tz":-60},"id":"W38mMNHRoypT"},"outputs":[],"source":["#code for resnet18 (18-layer ResNet)\n","DEFAULT_FILTER_SIZE = 3\n","INIT_LR = 1e-3\n","\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1642890272238,"user":{"displayName":"Mathieu Jacques","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuqmYelZ_Kv6yga8GgHY07sH9ye4ZTi2sODQXkhQ=s64","userId":"02992467458977810224"},"user_tz":-60},"id":"r7fJzTlyaDQy"},"outputs":[],"source":["def identity_block(input, f, filters, conv_num, step):\n","    \n","    # Names of layers\n","    conv_name_base = 'res_' + str(conv_num) + '_' + str(step)\n","    \n","    F1, F2 = filters\n","    \n","    # Save skip value\n","    x_skip = input\n","    \n","    # First component of main path\n","    x = layers.Conv2D(filters = F1, kernel_size = (f, f),\n","                      padding='same',\n","                      name = conv_name_base + '_a')(input)\n","\n","    x = layers.Activation('relu')(x)\n","    \n","    # Third component of main path \n","    x = layers.Conv2D(filters = F2, kernel_size = (f, f),\n","                      padding='same',\n","                      name = conv_name_base + '_b')(x)\n","\n","    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n","    x = layers.Add()([x, x_skip])\n","    x = layers.Activation('relu')(x)\n","    \n","    return x\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1642890272239,"user":{"displayName":"Mathieu Jacques","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuqmYelZ_Kv6yga8GgHY07sH9ye4ZTi2sODQXkhQ=s64","userId":"02992467458977810224"},"user_tz":-60},"id":"6AbED6u4uSK-"},"outputs":[],"source":["def conv_block(input, f, filters, conv_num, step, s=2):\n","    \n","    # Names of layers\n","    conv_name_base = 'res_' + str(conv_num) + '_' + str(step)\n","    \n","    F1, F2 = filters\n","    \n","    # Save skip value\n","    x_skip = input\n","    \n","    # First layer of main path\n","    x = layers.Conv2D(filters=F1, kernel_size=(f, f), strides=(s,s),\n","                      padding='same',\n","                      name=conv_name_base + '_a')(input)\n","\n","    x = layers.Activation('relu')(x)\n","\n","    # Second layer of main path \n","    x = layers.Conv2D(filters = F2, kernel_size = (f, f),\n","                      strides=(1,1),\n","                      padding='same',\n","                      name = conv_name_base + '_b')(x)\n","\n","\n","    # SKIP CONNECTION #\n","    x_skip = layers.Conv2D(filters=F2, kernel_size=(1, 1), strides=(s, s),\n","                    name=conv_name_base + '_1')(x_skip)\n","\n","    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n","    x = layers.Add()([x, x_skip])\n","    x = layers.Activation('relu')(x)\n","    \n","    return x"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1642890272239,"user":{"displayName":"Mathieu Jacques","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuqmYelZ_Kv6yga8GgHY07sH9ye4ZTi2sODQXkhQ=s64","userId":"02992467458977810224"},"user_tz":-60},"id":"d0UyRTnpv60G"},"outputs":[],"source":["def ResNet18(input_shape, classes):\n","  # Define the input as a tensor with shape input_shape\n","    x_input = layers.Input(input_shape)\n","    \n","    # Zero-Padding\n","    x = layers.ZeroPadding2D((3, 3))(x_input)\n","    \n","    # Conv 1\n","    x = layers.Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n","    x = layers.Activation('relu')(x)\n","    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n","\n","    # Conv 2\n","    x = conv_block(x, f=DEFAULT_FILTER_SIZE, filters=[64,64], conv_num=2, step=1, s=1)\n","    x = identity_block(x, f=DEFAULT_FILTER_SIZE, filters=[64,64], conv_num=2, step=2)\n","\n","    # Conv 3\n","    x = conv_block(x, f=DEFAULT_FILTER_SIZE, filters=[128,128], conv_num=3, step=1, s=2)\n","    x = identity_block(x, f=DEFAULT_FILTER_SIZE, filters=[128,128], conv_num=3, step=2)\n","\n","    # Conv 4\n","    x = conv_block(x, f=DEFAULT_FILTER_SIZE, filters=[256,256], conv_num=4, step=1)\n","    x = identity_block(x, f=DEFAULT_FILTER_SIZE, filters=[256,256], conv_num=4, step=2)\n","\n","    # Conv 5\n","    x = conv_block(x, f=DEFAULT_FILTER_SIZE, filters=[512,512], conv_num=5, step=1)\n","    x = identity_block(x, f=DEFAULT_FILTER_SIZE, filters=[512,512], conv_num=5, step=2)\n","\n","    #Pooling layer\n","    x = layers.AveragePooling2D(pool_size=(2,2), padding='same')(x)\n","\n","    # Output layer\n","    x = layers.Flatten()(x)\n","    output = layers.Dense(classes, activation='softmax', name='fc' + str(classes))(x)\n","\n","    model = Model(x_input, output, name=\"ResNet_18\")\n","\n","    model.compile(loss='categorical_crossentropy',\n","                optimizer=Adam(learning_rate=INIT_LR),\n","                metrics=['accuracy'])\n","\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"Xa1p7FRxrpS6"},"source":["#AGC implementation"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1642890272240,"user":{"displayName":"Mathieu Jacques","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuqmYelZ_Kv6yga8GgHY07sH9ye4ZTi2sODQXkhQ=s64","userId":"02992467458977810224"},"user_tz":-60},"id":"SokAiLYOrryW"},"outputs":[],"source":["import tensorflow as tf\n","\n","def compute_norm(x, axis, keepdims):\n","    return tf.math.reduce_sum(x ** 2, axis=axis, keepdims=keepdims) ** 0.5\n","\n","def unitwise_norm(x):\n","    if len(x.get_shape()) <= 1:  # Scalars and vectors\n","        axis = None\n","        keepdims = False\n","    elif len(x.get_shape()) in [2, 3]:  # Linear layers of shape IO or multihead linear\n","        axis = 0\n","        keepdims = True\n","    elif len(x.get_shape()) == 4:  # Conv kernels of shape HWIO\n","        axis = [0, 1, 2,]\n","        keepdims = True\n","    else:\n","        raise ValueError(f\"Got a parameter with shape not in [1, 2, 4]! {x}\")\n","    return compute_norm(x, axis, keepdims)\n","\n","\n","def adaptive_clip_grad(parameters, gradients, clip_factor=0.01,\n","                       eps=1e-3):\n","    new_grads = []\n","    for (params, grads) in zip(parameters, gradients):\n","        p_norm = unitwise_norm(params)\n","        max_norm = tf.math.maximum(p_norm, eps) * clip_factor\n","        grad_norm = unitwise_norm(grads)\n","        clipped_grad = grads * (max_norm / tf.math.maximum(grad_norm, 1e-6))\n","        new_grad = tf.where(grad_norm < max_norm, grads, clipped_grad)\n","        new_grads.append(new_grad)\n","    return new_grads"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1642890272241,"user":{"displayName":"Mathieu Jacques","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuqmYelZ_Kv6yga8GgHY07sH9ye4ZTi2sODQXkhQ=s64","userId":"02992467458977810224"},"user_tz":-60},"id":"lrQD3GLdr0sd"},"outputs":[],"source":["import tensorflow as tf\n","\n","class ResNet18_AGC_Model(Model):\n","\n","  def __init__(self, inputshape, name, threshold=1e-3):\n","        super(ResNet18_AGC_Model, self).__init__()\n","        self.threshold = threshold\n","        self.resnet = ResNet18(input_shape=inputshape, classes=10)\n","\n","  #this bit of code is from keras API\n","  def train_step(self, data):\n","    # Unpack the data\n","    images, y = data\n","\n","    with tf.GradientTape() as tape:\n","        y_pred = self.resnet(images)  # Forward pass\n","        # Compute the loss value\n","        loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n","\n","    # Compute gradients\n","    trainable_vars = self.resnet.trainable_variables\n","    gradients = tape.gradient(loss, trainable_vars)\n","    # Update gradients\n","    updated_grad = adaptive_clip_grad(trainable_vars, gradients, self.threshold)\n","    # Update weights\n","    self.optimizer.apply_gradients(zip(updated_grad, trainable_vars))\n","    # Update metrics (includes the metric that tracks the loss)\n","    self.compiled_metrics.update_state(y, y_pred)\n","    # Return a dict mapping metric names to current value\n","    return {m.name: m.result() for m in self.metrics}\n","\n","  def test_step(self, data):\n","    images, labels = data\n","    predictions = self.resnet(images, training=False)\n","    loss = self.compiled_loss(labels, predictions)\n","    self.compiled_metrics.update_state(labels, predictions)\n","    return {m.name: m.result() for m in self.metrics}\n","\n","  def call(self, inputs):\n","    return self.resnet(inputs)"]},{"cell_type":"markdown","metadata":{"id":"vkoI24RJtAtw"},"source":["#Model creation and training"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":258,"status":"ok","timestamp":1642890272486,"user":{"displayName":"Mathieu Jacques","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuqmYelZ_Kv6yga8GgHY07sH9ye4ZTi2sODQXkhQ=s64","userId":"02992467458977810224"},"user_tz":-60},"id":"TtxjQ5r-r90R"},"outputs":[],"source":["from tensorflow.keras.optimizers import Adam\n","clipping_factor = 0.08 # As described in the base paper of this study\n","resnet18 = ResNet18_AGC_Model((32,32,3), threshold=0.08, name='resnet18_agc')\n","\n","resnet18.compile(loss='categorical_crossentropy',\n","            optimizer=Adam(learning_rate=1e-3),\n","            metrics=['accuracy'])"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1642890272487,"user":{"displayName":"Mathieu Jacques","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuqmYelZ_Kv6yga8GgHY07sH9ye4ZTi2sODQXkhQ=s64","userId":"02992467458977810224"},"user_tz":-60},"id":"1ykSL87nHzSW"},"outputs":[],"source":["#@title `plot_history()` definition\n","from matplotlib import pyplot as plt\n","\n","def plot_history(history):\n","  fig, (ax1, ax2) = plt.subplots(2,1, sharex=True, dpi=150)\n","  ax1.plot(history.history['loss'], label='training')\n","  ax1.plot(history.history['val_loss'], label='validation')\n","  ax1.set_ylabel('Cross-Entropy Loss')\n","  ax1.set_yscale('log')\n","  if history.history.__contains__('lr'):\n","    ax1b = ax1.twinx()\n","    ax1b.plot(history.history['lr'], 'g-', linewidth=1)\n","    ax1b.set_yscale('log')\n","    ax1b.set_ylabel('Learning Rate', color='g')\n","\n","  ax2.plot(history.history['accuracy'], label='training')\n","  ax2.plot(history.history['val_accuracy'], label='validation')\n","  ax2.set_ylabel('Accuracy')\n","  ax2.set_xlabel('Epochs')\n","  ax2.legend()\n","  plt.show() "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3508151,"status":"ok","timestamp":1642893780633,"user":{"displayName":"Mathieu Jacques","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuqmYelZ_Kv6yga8GgHY07sH9ye4ZTi2sODQXkhQ=s64","userId":"02992467458977810224"},"user_tz":-60},"id":"6b-IR9h0H2y8","outputId":"8ad3dcf4-afd3-42f0-f088-770ec6a15d74"},"outputs":[],"source":["history = resnet18.fit(train_generator,\n","                        steps_per_epoch=train_steps,# trained with 512\n","                        epochs=100,\n","                        validation_data=test_generator,\n","                        validation_steps=test_steps\n","                       )\n","plot_history(history)"]}],"metadata":{"accelerator":"GPU","colab":{"name":"Resnet18_AGC.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
